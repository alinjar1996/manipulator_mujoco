{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mjx_planner import cem_planner\n",
    "import mujoco.mjx as mjx \n",
    "import mujoco\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import os\n",
    "from mujoco import viewer\n",
    "import matplotlib.pyplot as plt\n",
    "from quat_math import rotation_quaternion, quaternion_multiply, quaternion_distance\n",
    "import argparse\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from mlp_inference import rnn_inference\n",
    "from RNN.mlp_singledof_rnn import MLP, MLPProjectionFilter, CustomGRULayer, GRU_Hidden_State, CustomLSTMLayer, LSTM_Hidden_State\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scale(input_nn: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize input using median and IQR (Robust scaling).\n",
    "    \n",
    "    Args:\n",
    "        input_nn (jnp.ndarray): Input data of shape (batch_size, features)\n",
    "\n",
    "    Returns:\n",
    "        inp_norm (jnp.ndarray): Robustly normalized data\n",
    "    \"\"\"\n",
    "    inp_median_ = jnp.median(input_nn, axis=0)\n",
    "    inp_q1 = jnp.quantile(input_nn, 0.25, axis=0)\n",
    "    inp_q3 = jnp.quantile(input_nn, 0.75, axis=0)\n",
    "    inp_iqr_ = inp_q3 - inp_q1\n",
    "\n",
    "    # Handle constant features (IQR = 0)\n",
    "    inp_iqr_ = jnp.where(inp_iqr_ == 0, 1.0, inp_iqr_)\n",
    "\n",
    "    inp_norm = (input_nn - inp_median_) / inp_iqr_\n",
    "    return inp_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def compute_xi_samples(key, xi_mean, xi_cov, nvar, num_batch ):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    xi_samples = jax.random.multivariate_normal(key, xi_mean, xi_cov+0.003*jnp.identity(nvar), (num_batch, ))\n",
    "    return xi_samples, key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mlp_projection_model(\n",
    "    inp, inp_norm, rnn_type, num_total_constraints, nvar, num_batch, num_dof, num_steps,\n",
    "    timestep, cem, maxiter_projection, device='cuda'):\n",
    "\n",
    "    enc_inp_dim = np.shape(inp)[1]\n",
    "    mlp_inp_dim = enc_inp_dim\n",
    "    hidden_dim = 1024\n",
    "    mlp_out_dim = 2 * nvar + num_total_constraints\n",
    "\n",
    "    if rnn_type == \"GRU\":\n",
    "        print(\"Training with GRU\")\n",
    "        rnn_input_size = 3 * num_total_constraints + 3 * nvar\n",
    "        rnn_hidden_size = 512\n",
    "        rnn_output_size = num_total_constraints + nvar\n",
    "        rnn_context = CustomGRULayer(rnn_input_size, rnn_hidden_size, rnn_output_size)\n",
    "        rnn_init = GRU_Hidden_State(mlp_inp_dim, rnn_hidden_size, rnn_hidden_size)\n",
    "\n",
    "    elif rnn_type == \"LSTM\":\n",
    "        print(\"Training with LSTM\")\n",
    "        rnn_input_size = 3 * num_total_constraints + 3 * nvar\n",
    "        rnn_hidden_size = 512\n",
    "        rnn_output_size = num_total_constraints + nvar\n",
    "        rnn_context = CustomLSTMLayer(rnn_input_size, rnn_hidden_size, rnn_output_size)\n",
    "        rnn_init = LSTM_Hidden_State(mlp_inp_dim, rnn_hidden_size, rnn_hidden_size)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported RNN type: {rnn_type}\")\n",
    "\n",
    "    mlp = MLP(mlp_inp_dim, hidden_dim, mlp_out_dim)\n",
    "\n",
    "    model = MLPProjectionFilter(\n",
    "        mlp=mlp,\n",
    "        rnn_context=rnn_context,\n",
    "        rnn_init=rnn_init,\n",
    "        num_batch=num_batch,\n",
    "        num_dof=num_dof,\n",
    "        num_steps=num_steps,\n",
    "        timestep=timestep,\n",
    "        v_max=cem.v_max,\n",
    "        a_max=cem.a_max,\n",
    "        j_max=5.0,\n",
    "        p_max=cem.p_max,\n",
    "        maxiter_projection=maxiter_projection,\n",
    "        rnn=rnn_type\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model type: {type(model)}\")\n",
    "    \n",
    "    current_working_directory = os.getcwd()\n",
    "    print(current_working_directory)\n",
    "    \n",
    "    weight_path = f'./training_weights/mlp_learned_single_dof_{rnn_type}.pth'\n",
    "    model.load_state_dict(torch.load(weight_path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    # Run forward pass\n",
    "    neural_output_batch = model.mlp(inp_norm)\n",
    "\n",
    "    return model, neural_output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cem_planner(\n",
    "    # CEM planner parameters\n",
    "    num_dof=None,\n",
    "    num_batch=None,\n",
    "    num_steps=None,\n",
    "    maxiter_cem=None,\n",
    "    maxiter_projection=None,\n",
    "    w_pos=None,\n",
    "    w_rot=None,\n",
    "    w_col=None,\n",
    "    num_elite=None,\n",
    "    timestep=None,\n",
    "    # Robot initial configuration\n",
    "    initial_qpos=None,\n",
    "    # Target configuration\n",
    "    target_names=None,\n",
    "    # Visualization options\n",
    "    show_viewer=None,\n",
    "    cam_distance=None,\n",
    "    show_contact_points=None,\n",
    "    # Convergence criteria\n",
    "    position_threshold=None,\n",
    "    rotation_threshold=None,\n",
    "    # Save data\n",
    "    save_data=None,\n",
    "    data_dir=None,\n",
    "    # Motion control\n",
    "    stop_at_final_target=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run CEM planner with configurable parameters\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_dof : int\n",
    "        Number of degrees of freedom for the robot\n",
    "    num_batch : int\n",
    "        Number of samples in each CEM iteration\n",
    "    num_steps : int\n",
    "        Number of steps in the planning horizon\n",
    "    maxiter_cem : int\n",
    "        Maximum number of CEM iterations\n",
    "    w_pos : float\n",
    "        Weight for position error in the cost function\n",
    "    w_rot : float\n",
    "        Weight for rotation error in the cost function\n",
    "    w_col : float\n",
    "        Weight for collision penalty in the cost function\n",
    "    num_elite : float\n",
    "        Fraction of samples to use as elite samples\n",
    "    timestep : float\n",
    "        Time step for simulation\n",
    "    initial_qpos : array-like or None\n",
    "        Initial joint positions, if None uses [1.5, -1.8, 1.75, -1.25, -1.6, 0]\n",
    "    target_names : list of str or None\n",
    "        Names of targets to reach in sequence, if None uses [\"target_0\", \"target_1\", \"home\"]\n",
    "    show_viewer : bool\n",
    "        Whether to show the MuJoCo viewer\n",
    "    cam_distance : float\n",
    "        Camera distance in the viewer\n",
    "    show_contact_points : bool\n",
    "        Whether to show contact points in the viewer\n",
    "    position_threshold : float\n",
    "        Threshold for position convergence\n",
    "    rotation_threshold : float\n",
    "        Threshold for rotation convergence\n",
    "    save_data : bool\n",
    "        Whether to save data to CSV files\n",
    "    data_dir : str\n",
    "        Directory to save data\n",
    "    stop_at_final_target : bool\n",
    "        Whether to stop at the final target or loop back to the first target\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the directory for data if it doesn't exist and save_data is True\n",
    "    if save_data:\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize the CEM planner\n",
    "    start_time = time.time()\n",
    "    cem = cem_planner(\n",
    "        num_dof=num_dof, \n",
    "        num_batch=num_batch, \n",
    "        num_steps=num_steps, \n",
    "        maxiter_cem=maxiter_cem,\n",
    "        w_pos=w_pos,\n",
    "        w_rot=w_rot,\n",
    "        w_col=w_col,\n",
    "        num_elite=num_elite,\n",
    "        timestep=timestep,\n",
    "        maxiter_projection=maxiter_projection\n",
    "    )\n",
    "    print(f\"Initialized CEM Planner: {round(time.time()-start_time, 2)}s\")\n",
    "\n",
    "    # Get model and data\n",
    "    model = cem.model\n",
    "    data = cem.data\n",
    "    \n",
    "    # Set initial joint positions\n",
    "    data.qpos[:num_dof] = jnp.array(initial_qpos)\n",
    "    mujoco.mj_forward(model, data)\n",
    "    \n",
    "    # Initialize CEM mean and covariance\n",
    "    xi_mean_single = jnp.zeros(cem.nvar_single)\n",
    "    xi_cov_single = 10*jnp.identity(cem.nvar_single)\n",
    "\n",
    "    xi_mean = jnp.zeros((cem.nvar))\n",
    "    xi_cov = 10*jnp.identity(cem.nvar)\n",
    "\n",
    "    #Initialize lamda and s\n",
    "    lamda_init = jnp.zeros(( cem.num_batch, 3*cem.nvar_single  ))\n",
    "    s_init = jnp.zeros((cem.num_batch, 6*cem.num))\n",
    "    \n",
    "    # Get initial end-effector position and orientation\n",
    "    init_position = data.site_xpos[model.site(name=\"tcp\").id].copy()\n",
    "    init_rotation = data.xquat[model.body(name=\"hande\").id].copy()\n",
    "\n",
    "    # First target for test computation\n",
    "    target_pos = model.body(name=target_names[0]).pos\n",
    "    target_rot = model.body(name=target_names[0]).quat\n",
    "\n",
    "    # Warm-up computation\n",
    "    start_time = time.time()\n",
    "    _ = cem.compute_cem(xi_mean, data.qpos[:num_dof], data.qvel[:num_dof], data.qacc[:num_dof], target_pos, target_rot, lamda_init, s_init)\n",
    "    print(f\"Compute CEM: {round(time.time()-start_time, 2)}s\")\n",
    "\n",
    "    # Initialize variables for data collection\n",
    "    thetadot = np.array([0] * num_dof)\n",
    "    cost_g_list = []\n",
    "    cost_list = []\n",
    "    cost_r_list = []\n",
    "    cost_c_list = []\n",
    "    thetadot_list = []\n",
    "    theta_list = []\n",
    "    \n",
    "    # Current target index\n",
    "    target_idx = 0\n",
    "    current_target = target_names[target_idx]\n",
    "    \n",
    "        # Run the control loop\n",
    "    if show_viewer:\n",
    "        with viewer.launch_passive(model, data) as viewer_:\n",
    "            viewer_.cam.distance = cam_distance\n",
    "            viewer_.opt.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = show_contact_points\n",
    "            \n",
    "            while viewer_.is_running():\n",
    "                # Time the step\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Determine target position and orientation\n",
    "                if current_target != \"home\":\n",
    "                    target_pos = model.body(name=current_target).pos\n",
    "                    target_rot = model.body(name=current_target).quat\n",
    "                else:\n",
    "                    target_pos = init_position\n",
    "                    target_rot = init_rotation\n",
    "\n",
    "                # Special case for target_1 (moving target with end-effector)\n",
    "                if current_target == \"target_1\" and \"target_0\" in target_names:\n",
    "                    model.body(name=\"target_0\").pos = data.site_xpos[cem.tcp_id]\n",
    "                    model.body(name=\"target_0\").quat = data.xquat[cem.hande_id]\n",
    "\n",
    "                # Compute CEM control\n",
    "                # Compute raw samples from mean and covariance\n",
    "                # Pass raw sample through to Network\n",
    "                #Raw sample and initialize\n",
    "                 \n",
    "                #rnn_inference(rnn_type=\"LSTM\", model_weights_path=None, dataset_size=1000):\n",
    "\n",
    "                key = cem.key #jax.random.PRNGKey(42)\n",
    "                xi_samples_single, key = compute_xi_samples(key, xi_mean_single, xi_cov_single, cem.nvar_single, cem.num_batch)\n",
    "                \n",
    "                rnn = 'LSTM'\n",
    "\n",
    "                for i in range(cem.num_dof):\n",
    "                    theta_init = data.qpos[i]\n",
    "                    v_start = data.qvel[i]\n",
    "\n",
    "                    theta_init = np.tile(data.qpos[i], (num_batch,1))\n",
    "                    v_start = np.tile(data.qvel[i], (num_batch,1)) \n",
    "\n",
    "                    # Goal Velocity is not used in current model\n",
    "                    v_goal = np.tile(0.0, (num_batch,1))\n",
    "\n",
    "                    inp = np.hstack([xi_samples_single, theta_init, v_start, v_goal])\n",
    "                    inp_norm = robust_scale(inp)\n",
    "\n",
    "                    print(\"inp_norm.shape\", inp_norm.shape)\n",
    "                    \n",
    "                    model, neural_output_batch = load_mlp_projection_model(inp, inp_norm, rnn, \n",
    "                                                                       cem.num_total_constraints, cem.nvar_single, num_batch, num_dof, num_steps,\n",
    "                                                                       timestep, cem, maxiter_projection, device= device)\n",
    "                    \n",
    "                    xi_projected_output_nn = neural_output_batch[:, :cem.nvar_single]\n",
    "                    lamda_init_nn_output = neural_output_batch[:, cem.nvar_single: 2*cem.nvar_single]\n",
    "                    s_init_nn_output = neural_output_batch[:, 2*cem.nvar_single: 2*cem.nvar_single + cem.num_total_constraints]\n",
    "\n",
    "                    print(f\"xi_projected_output_nn: {xi_projected_output_nn.shape}\")\n",
    "                    print(f\"lamda: {lamda_init_nn_output.shape}\")\n",
    "                    print(f\"s: {s_init_nn_output.shape}\")\n",
    "\n",
    "                    print(f\"{i}th joint value inference\")\n",
    "                \n",
    "\n",
    "                cost, best_cost_g, best_cost_r, best_cost_c, best_vels, best_traj, xi_mean, xi_cov = cem.compute_cem(\n",
    "                    xi_mean, data.qpos[:num_dof], data.qvel[:num_dof], \n",
    "                    data.qacc[:num_dof], target_pos, target_rot,\n",
    "                    lambda_init=lamda_init_nn_output, \n",
    "                    s_init=s_init_nn_output\n",
    "                )\n",
    "                \n",
    "                # Apply the control (use average of planned velocities)\n",
    "                thetadot = np.mean(best_vels[1:num_steps-2], axis=0)\n",
    "                data.qvel[:num_dof] = thetadot\n",
    "                mujoco.mj_step(model, data)\n",
    "\n",
    "                # Calculate costs\n",
    "                current_cost_g = np.linalg.norm(data.site_xpos[cem.tcp_id] - target_pos)   \n",
    "                current_cost_r = quaternion_distance(data.xquat[cem.hande_id], target_rot)  \n",
    "                current_cost = np.round(cost, 2)\n",
    "                \n",
    "                # Print status\n",
    "\n",
    "                print(f'Step Time: {\"%.0f\"%((time.time() - start_time)*1000)}ms | Cost g: {\"%.2f\"%(float(current_cost_g))}'\n",
    "                      f' | Cost r: {\"%.2f\"%(float(current_cost_r))} | Cost c: {\"%.2f\"%(float(best_cost_c))} | Cost: {current_cost}')\n",
    "                print(f'eef_quat: {data.xquat[cem.hande_id]}')\n",
    "                print(f'target: {current_target}')\n",
    "                \n",
    "                # Update viewer\n",
    "                viewer_.sync()\n",
    "\n",
    "                # Check if target is reached based on thresholds\n",
    "                if current_cost_g < position_threshold and current_cost_r < rotation_threshold:\n",
    "                    # Check if this was the last target\n",
    "                    if target_idx == len(target_names) - 1:\n",
    "                        if stop_at_final_target:\n",
    "                            print(f\"Reached final target: {current_target}. Stopping motion.\")\n",
    "                            # Hold position by setting velocities to zero\n",
    "                            thetadot = np.zeros(num_dof)\n",
    "                            data.qvel[:num_dof] = thetadot\n",
    "                        else:\n",
    "                            # Loop back to first target\n",
    "                            target_idx = 0\n",
    "                            current_target = target_names[target_idx]\n",
    "                            print(f\"Reached final target. Looping back to first target: {current_target}\")\n",
    "                    else:\n",
    "                        # Move to next target\n",
    "                        target_idx = target_idx + 1\n",
    "                        current_target = target_names[target_idx]\n",
    "                        print(f\"Moving to next target: {current_target}\")\n",
    "                    \n",
    "                    # If transitioning to home, save current position for reference\n",
    "                    if current_target == \"home\" and \"target_0\" in target_names:\n",
    "                        model.body(name=\"target_0\").pos = data.site_xpos[cem.tcp_id].copy()\n",
    "                        model.body(name=\"target_0\").quat = data.xquat[cem.hande_id].copy()\n",
    "\n",
    "                # Store data\n",
    "                cost_g_list.append(best_cost_g)\n",
    "                cost_r_list.append(best_cost_r)\n",
    "                cost_c_list.append(best_cost_c)\n",
    "                thetadot_list.append(thetadot)\n",
    "                theta_list.append(data.qpos[:num_dof].copy())\n",
    "                cost_list.append(current_cost[-1] if isinstance(current_cost, np.ndarray) else current_cost)\n",
    "\n",
    "                # Sleep to maintain simulation speed\n",
    "                time_until_next_step = model.opt.timestep - (time.time() - start_time)\n",
    "                if time_until_next_step > 0:\n",
    "                    time.sleep(time_until_next_step)\n",
    "    else:\n",
    "        # Non-visualization mode would go here if needed\n",
    "        print(\"Running without visualization is not implemented yet.\")\n",
    "        \n",
    "    # Save data if requested\n",
    "    if save_data:\n",
    "        np.savetxt(f'{data_dir}/costs.csv', cost_list, delimiter=\",\")\n",
    "        np.savetxt(f'{data_dir}/thetadot.csv', thetadot_list, delimiter=\",\")\n",
    "        np.savetxt(f'{data_dir}/theta.csv', theta_list, delimiter=\",\")\n",
    "        np.savetxt(f'{data_dir}/cost_g.csv', cost_g_list, delimiter=\",\")\n",
    "        np.savetxt(f'{data_dir}/cost_r.csv', cost_r_list, delimiter=\",\")\n",
    "        np.savetxt(f'{data_dir}/cost_c.csv', cost_c_list, delimiter=\",\")\n",
    "    \n",
    "    return {\n",
    "        'cost_g': cost_g_list,\n",
    "        'cost_r': cost_r_list,\n",
    "        'cost_c': cost_c_list,\n",
    "        'cost': cost_list,\n",
    "        'thetadot': thetadot_list,\n",
    "        'theta': theta_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Default backend: gpu\n",
      " Model path: /home/alinjar/manipulator/manipulator_mujoco/sampling_based_planner/ur5e_hande_mjx/scene.xml \n",
      " Timestep: 0.05 \n",
      " CEM Iter: 1 \n",
      " Number of batches: 1000 \n",
      " Number of steps per trajectory: 50 \n",
      " Time per trajectory: 2.5\n",
      "Initialized CEM Planner: 11.81s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cem_planner.compute_cem() missing 1 required positional argument: 's_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mrun_cem_planner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# CEM parameters\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_dof\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use More samples for better optimization\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Use More steps for longer planning horizon\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_elite\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Use More elite samples for better convergence #Int(num_elite*num_batch) is used to select elite samples\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Simulation Time Step Use Smaller timestep for more accurate simulation\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxiter_cem\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# CEM iterations: Use More iterations for better convergence     \u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxiter_projection\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Projection Filter iterations: Use More iterations for better Filtering\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# weight on position error\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw_rot\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# weight on rotation error\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# weight on collision avoidance\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#Shower parameters\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_viewer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_contact_points\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Initial configuration\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_qpos\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Target sequence\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhome\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Visualization\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcam_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# View \u001b[39;49;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Convergence thresholds\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.08\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stricter position convergence Better for more complex tasks\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrotation_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Stricter rotation convergence Better for more complex tasks\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Save data\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcustom_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#Stop at final target\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_at_final_target\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mrun_cem_planner\u001b[39m\u001b[34m(num_dof, num_batch, num_steps, maxiter_cem, maxiter_projection, w_pos, w_rot, w_col, num_elite, timestep, initial_qpos, target_names, show_viewer, cam_distance, show_contact_points, position_threshold, rotation_threshold, save_data, data_dir, stop_at_final_target)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Warm-up computation\u001b[39;00m\n\u001b[32m    123\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m _ = \u001b[43mcem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_cem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_dof\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqvel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_dof\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqacc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_dof\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_rot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompute CEM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time.time()-start_time,\u001b[38;5;250m \u001b[39m\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Initialize variables for data collection\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 15 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manipulator_torch_env/lib/python3.12/site-packages/jax/_src/linear_util.py:388\u001b[39m, in \u001b[36m_get_result_paths_thunk\u001b[39m\u001b[34m(_fun, _store, *args, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m   ans = \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m   result_paths = \u001b[38;5;28mtuple\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[32m    390\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: cem_planner.compute_cem() missing 1 required positional argument: 's_init'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "results = run_cem_planner(\n",
    "    # CEM parameters\n",
    "    num_dof=6,\n",
    "    num_batch=1000,  # Use More samples for better optimization\n",
    "    num_steps=50,     # Use More steps for longer planning horizon\n",
    "    num_elite=0.05,   # Use More elite samples for better convergence #Int(num_elite*num_batch) is used to select elite samples\n",
    "    timestep=0.05,     # Simulation Time Step Use Smaller timestep for more accurate simulation\n",
    "    \n",
    "    maxiter_cem=1,      # CEM iterations: Use More iterations for better convergence     \n",
    "    maxiter_projection=20,   # Projection Filter iterations: Use More iterations for better Filtering\n",
    "    w_pos=20.0,      # weight on position error\n",
    "    w_rot=3.0,       # weight on rotation error\n",
    "    w_col=80.0,      # weight on collision avoidance\n",
    "    \n",
    "    #Shower parameters\n",
    "    show_viewer=True,\n",
    "    show_contact_points=True,\n",
    "    \n",
    "    # Initial configuration\n",
    "    initial_qpos=[1.5, -1.8, 1.75, -1.25, -1.6, 0],\n",
    "    \n",
    "    # Target sequence\n",
    "    target_names=[\"target_0\", \"target_1\", \"target_2\", \"home\"],\n",
    "    \n",
    "    # Visualization\n",
    "    cam_distance=4,  # View \n",
    "    \n",
    "    # Convergence thresholds\n",
    "    position_threshold=0.08,  # Stricter position convergence Better for more complex tasks\n",
    "    rotation_threshold=0.1,   # Stricter rotation convergence Better for more complex tasks\n",
    "    \n",
    "    # Save data\n",
    "    save_data=True,\n",
    "    data_dir='custom_data',\n",
    "\n",
    "    #Stop at final target\n",
    "    stop_at_final_target=True \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manipulator_torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
