{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('./src/terrain_mlp/fft_new/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from tqdm import tqdm,trange    \n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models.flow_model_v7 import Flow\n",
    "import open3d as o3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_float32_matmul_precision('high')\n",
    "\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "test = 'v7_500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 500\n",
    "LEARNING_RATE   = 1e-3\n",
    "SEED            = 0\n",
    "DEVICE          = 'cuda'      \n",
    "NUM_EPOCH       = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(seed=SEED)\n",
    "th.cuda.manual_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajDataset(Dataset):\n",
    "    def __init__(self, x_fin_data, y_fin_data, theta_init_data, theta_fin_data, x_data, y_data, index_data):\n",
    "        \n",
    "        # goal\n",
    "        self.x_fin = x_fin_data\n",
    "        self.y_fin = y_fin_data\n",
    "        self.theta_init = theta_init_data\n",
    "        self.theta_fin = theta_fin_data\n",
    "        # gt values\n",
    "        self.gt_x = x_data\n",
    "        self.gt_y = y_data\n",
    "        # index\n",
    "        self.index = index_data\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_fin)    \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        x_fin = self.x_fin[idx] \n",
    "        y_fin = self.y_fin[idx] \n",
    "        theta_init = self.theta_init[idx] \n",
    "        theta_fin = self.theta_fin[idx] \n",
    "        gt_x = self.gt_x[idx] \n",
    "        gt_y = self.gt_y[idx] \n",
    "        index = self.index[idx]\n",
    "                 \n",
    "        return th.tensor(x_fin).float(), th.tensor(y_fin).float(), th.tensor(theta_init).float(), th.tensor(theta_fin).float(), th.tensor(gt_x).float(), \\\n",
    "            th.tensor(gt_y).float(), index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.load(\"./dataset/data_train_pcd_gd.npz\")\n",
    "\n",
    "lam_data = data_set[\"lam\"]\n",
    "p1_data = data_set[\"p1\"]\n",
    "p2_data = data_set[\"p2\"]\n",
    "p3_data = data_set[\"p3\"]\n",
    "p4_data = data_set[\"p4\"]\n",
    "cov_data = data_set[\"cov\"]\n",
    "x_fin_data = data_set[\"x_fin\"]\n",
    "y_fin_data = data_set[\"y_fin\"]\n",
    "theta_init_data = data_set[\"theta_init\"]\n",
    "theta_fin_data = data_set[\"theta_fin\"]\n",
    "x_data = data_set[\"x\"]\n",
    "y_data = data_set[\"y\"]\n",
    "pcd_data = data_set[\"pcd\"]\n",
    "index_data = data_set[\"index\"]\n",
    "\n",
    "terrain_params = np.concatenate((p1_data, p2_data, p3_data, p4_data), axis=1)\n",
    "\n",
    "theta_init_mean, theta_init_std = th.tensor(theta_init_data.mean()).to(DEVICE), th.tensor(theta_init_data.std()).to(DEVICE)\n",
    "theta_fin_mean, theta_fin_std = th.tensor(theta_fin_data.mean()).to(DEVICE), th.tensor(theta_fin_data.std()).to(DEVICE)\n",
    "x_fin_mean, x_fin_std = th.tensor(x_fin_data.mean()).to(DEVICE), th.tensor(x_fin_data.std()).to(DEVICE)\n",
    "y_fin_mean, y_fin_std = th.tensor(y_fin_data.mean()).to(DEVICE), th.tensor(y_fin_data.std()).to(DEVICE)\n",
    "lam_mean, lam_std = th.tensor(lam_data.mean()).to(DEVICE), th.tensor(lam_data.std()).to(DEVICE)\n",
    "terrain_params_mean, terrain_params_std = th.tensor(terrain_params.mean()).to(DEVICE), th.tensor(terrain_params.std()).to(DEVICE)\n",
    "cov_mean, cov_std = th.tensor(cov_data.mean()).to(DEVICE), th.tensor(cov_data.std()).to(DEVICE)\n",
    "\n",
    "# #downsample pcd\n",
    "# N = 15000\n",
    "# down_pcd = np.zeros((pcd_data.shape[0], N, 3), dtype=np.float32)\n",
    "# for i in range(pcd_data.shape[0]):\n",
    "#     current_pcd = pcd_data[i,:,:]\n",
    "#     indices = np.random.choice(len(current_pcd), N, replace=False)\n",
    "#     down_pcd[i,:,:] = current_pcd[indices]\n",
    "# pcd_data = down_pcd.transpose(0,2,1)\n",
    "\n",
    "pcd_data = pcd_data.transpose(0,2,1)\n",
    "\n",
    "dataset = TrajDataset( x_fin_data, y_fin_data, theta_init_data, theta_fin_data, x_data, y_data, index_data)\n",
    "print(len(dataset))\n",
    "\n",
    "train_size = int(0.9 * len(dataset))  \n",
    "test_size = len(dataset) - train_size  \n",
    "\n",
    "# Create a generator with a fixed seed\n",
    "generator = th.Generator().manual_seed(0)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_chan = 512\n",
    "\n",
    "flow = Flow(out_chan,theta_init_mean,theta_init_std,theta_fin_mean,theta_fin_std,x_fin_mean,x_fin_std,y_fin_mean,y_fin_std,lam_mean,lam_std,\n",
    "            terrain_params_mean,terrain_params_std,cov_mean,cov_std).cuda()\n",
    "\n",
    "loss_fn = th.nn.MSELoss()\n",
    "optimizer = th.optim.AdamW(flow.parameters(), lr=LEARNING_RATE)\n",
    "# scheduler = th.optim.lr_scheduler.StepLR(optimizer, step_size = 1000, gamma = 0.1)\n",
    "\n",
    "# flow.load_state_dict(th.load(f\"./weights/test_v5_4.pt\"))\n",
    "# optimizer.load_state_dict(th.load(f\"./opts/test_v5_4.pt\"))\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     param_group['lr'] = LEARNING_RATE\n",
    "\n",
    "flow.train()\n",
    "c_flow = th.compile(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_losses = []\n",
    "last_loss = th.inf\n",
    "\n",
    "for epoch in trange(NUM_EPOCH):\n",
    "\tlosses = []\n",
    "\t\n",
    "\tfor (x_fin,y_fin,theta_init,theta_fin,gt_x,gt_y,index) in train_loader:\n",
    "\n",
    "\t\tx_fin = x_fin.to(DEVICE)\n",
    "\t\ty_fin = y_fin.to(DEVICE)\n",
    "\t\ttheta_init = theta_init.to(DEVICE)\n",
    "\t\ttheta_fin = theta_fin.to(DEVICE)\n",
    "\t\tgt_x = gt_x.to(DEVICE)\n",
    "\t\tgt_y = gt_y.to(DEVICE)\n",
    "\t\tlam = th.tensor(lam_data[index]).float().to(DEVICE)\n",
    "\t\tp1 = th.tensor(p1_data[index]).float().to(DEVICE)\n",
    "\t\tp2 = th.tensor(p2_data[index]).float().to(DEVICE)\n",
    "\t\tp3 = th.tensor(p3_data[index]).float().to(DEVICE)\n",
    "\t\tp4 = th.tensor(p4_data[index]).float().to(DEVICE)\n",
    "\t\tcov = th.tensor(cov_data[index]).float().to(DEVICE)\n",
    "\t\tpcd = th.tensor(pcd_data[index]).float().to(DEVICE)\n",
    "\n",
    "\t\tterrain_data = [theta_init, theta_fin, x_fin, y_fin, lam, th.hstack([p1,p2,p3,p4]), cov]\n",
    "\n",
    "\t\tx_1 = th.stack([gt_x,gt_y], dim=1)\n",
    "\t\tx_0 = th.randn_like(x_1)\n",
    "\t\tt = th.rand(len(x_1), 1, 1).to(device=DEVICE)\n",
    "\t\tx_t = (1 - t) * x_0 + t * x_1\n",
    "\t\tdx_t = x_1 - x_0\n",
    "\t\n",
    "\t\tloss = loss_fn(c_flow(x_t, terrain_data, t, pcd), dx_t)\n",
    "\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\n",
    "\tmean_loss = np.mean(losses)\n",
    "\tavg_losses.append(mean_loss)\n",
    "\t# scheduler.step()\n",
    "\n",
    "\tif epoch % 50 == 0:\n",
    "\t\tprint(f\"Epoch: {epoch + 1}, Train Loss: {mean_loss:.3f}\")\n",
    "\twriter.add_scalar('test_{}'.format(test), loss, epoch)\n",
    "\n",
    "\tif loss <= last_loss:\n",
    "\t\tth.save(flow.state_dict(), f\"./weights/test_{test}_lowest.pt\")\n",
    "\t\tth.save(optimizer.state_dict(), f\"./opts/test_{test}_lowest.pt\")\n",
    "\t\tlast_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(flow.state_dict(), './weights/test_{}.pt'.format(test))\n",
    "th.save(optimizer.state_dict(),'./opts/test_{}.pt'.format(test))\n",
    "\n",
    "np.savez(\n",
    "    \"./out_data/data_out_test_{}.npz\".format(test),\n",
    "    theta_init_mean=theta_init_mean.detach().cpu().numpy(),\n",
    "    theta_init_std=theta_init_std.detach().cpu().numpy(),\n",
    "    theta_fin_mean=theta_fin_mean.detach().cpu().numpy(),\n",
    "    theta_fin_std=theta_fin_std.detach().cpu().numpy(),\n",
    "    x_fin_mean=x_fin_mean.detach().cpu().numpy(),\n",
    "    x_fin_std=x_fin_std.detach().cpu().numpy(),\n",
    "    y_fin_mean=y_fin_mean.detach().cpu().numpy(),\n",
    "    y_fin_std=y_fin_std.detach().cpu().numpy(),\n",
    "    lam_mean=lam_mean.detach().cpu().numpy(),\n",
    "    lam_std=lam_std.detach().cpu().numpy(),\n",
    "    terrain_params_mean=terrain_params_mean.detach().cpu().numpy(),\n",
    "    terrain_params_std=terrain_params_std.detach().cpu().numpy(),\n",
    "    cov_mean=cov_mean.detach().cpu().numpy(),\n",
    "    cov_std=cov_std.detach().cpu().numpy(),\n",
    "    avg_losses=np.array(avg_losses),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epoch=NUM_EPOCH,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.load_state_dict(th.load(f\"./weights/test_{test}.pt\"))\n",
    "# flow.load_state_dict(th.load(f\"./weights/test_{test}_lowest.pt\"))\n",
    "\n",
    "flow.eval()\n",
    "\n",
    "x_fin,y_fin,theta_init,theta_fin,gt_x,gt_y,index = next(iter(train_loader))\n",
    "\n",
    "lam = th.tensor(lam_data[index]).float().to(DEVICE)\n",
    "p1 = th.tensor(p1_data[index]).float().to(DEVICE)\n",
    "p2 = th.tensor(p2_data[index]).float().to(DEVICE)\n",
    "p3 = th.tensor(p3_data[index]).float().to(DEVICE)\n",
    "p4 = th.tensor(p4_data[index]).float().to(DEVICE)\n",
    "cov = th.tensor(cov_data[index]).float().to(DEVICE)\n",
    "pcd = th.tensor(pcd_data[index]).float().to(DEVICE)\n",
    "x_fin = x_fin.to(DEVICE)\n",
    "y_fin = y_fin.to(DEVICE)\n",
    "theta_init = theta_init.to(DEVICE)\n",
    "theta_fin = theta_fin.to(DEVICE)\n",
    "gt_x = gt_x.to(DEVICE)\n",
    "gt_y = gt_y.to(DEVICE)\n",
    "\n",
    "terrain_data = [theta_init, theta_fin, x_fin, y_fin, lam, th.hstack([p1,p2,p3,p4]), cov]\n",
    "\n",
    "n_steps = 16\n",
    "x_1 = th.stack([gt_x,gt_y], dim=1)\n",
    "x_0 = th.randn_like(x_1)\n",
    "time_steps = th.linspace(0, 1.0, n_steps + 1, device=DEVICE).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "x = x_0.clone()\n",
    "fig = plt.figure(figsize=(15, 15)) \n",
    "for t in range(n_steps):\n",
    "\tax = fig.add_subplot(4, 4, t+1)\n",
    "\t\n",
    "\twith th.inference_mode():\n",
    "\t\tx = flow.step(x, terrain_data, time_steps[t].expand(x_0.shape[0],-1,-1), time_steps[t + 1].expand(x_0.shape[0],-1,-1), pcd)\n",
    "\n",
    "\tax.scatter(x[0, 0, :].detach().cpu().numpy(), x[0, 1, :].detach().cpu().numpy())\n",
    "\tax.plot(0, 0, 'og', markersize=5)\n",
    "\tax.plot(x_fin[0].detach().cpu().numpy(), y_fin[0].detach().cpu().numpy(), 'or', markersize=5)\n",
    "\tax.plot(gt_x[0, :].detach().cpu().numpy(), gt_y[0, :].detach().cpu().numpy(), 'r')\n",
    "\n",
    "\tax.axis('equal')\n",
    "\tax.set_title(f'timestep: {t}')\n",
    "\tax.grid(\"both\", linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
